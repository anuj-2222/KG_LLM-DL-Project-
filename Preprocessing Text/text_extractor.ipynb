{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 completed. Number of PDFs iterated: 100\n",
      "Chunk 2 completed. Number of PDFs iterated: 200\n",
      "Chunk 3 completed. Number of PDFs iterated: 300\n",
      "Chunk 4 completed. Number of PDFs iterated: 400\n",
      "Chunk 5 completed. Number of PDFs iterated: 500\n",
      "Chunk 6 completed. Number of PDFs iterated: 600\n",
      "Chunk 7 completed. Number of PDFs iterated: 700\n",
      "Chunk 8 completed. Number of PDFs iterated: 800\n",
      "Chunk 9 completed. Number of PDFs iterated: 900\n",
      "Chunk 10 completed. Number of PDFs iterated: 1000\n",
      "Chunk 11 completed. Number of PDFs iterated: 1100\n",
      "Chunk 12 completed. Number of PDFs iterated: 1200\n",
      "Chunk 13 completed. Number of PDFs iterated: 1300\n",
      "Chunk 14 completed. Number of PDFs iterated: 1400\n",
      "Chunk 15 completed. Number of PDFs iterated: 1500\n",
      "Chunk 16 completed. Number of PDFs iterated: 1600\n",
      "Chunk 17 completed. Number of PDFs iterated: 1700\n",
      "Chunk 18 completed. Number of PDFs iterated: 1800\n",
      "Chunk 19 completed. Number of PDFs iterated: 1900\n",
      "Chunk 20 completed. Number of PDFs iterated: 2000\n",
      "Chunk 21 completed. Number of PDFs iterated: 2100\n",
      "Chunk 22 completed. Number of PDFs iterated: 2200\n",
      "Chunk 23 completed. Number of PDFs iterated: 2300\n",
      "Chunk 24 completed. Number of PDFs iterated: 2400\n",
      "Chunk 25 completed. Number of PDFs iterated: 2500\n",
      "Chunk 26 completed. Number of PDFs iterated: 2600\n",
      "Chunk 27 completed. Number of PDFs iterated: 2700\n",
      "Chunk 28 completed. Number of PDFs iterated: 2800\n",
      "Chunk 29 completed. Number of PDFs iterated: 2900\n",
      "Chunk 30 completed. Number of PDFs iterated: 3000\n",
      "Chunk 31 completed. Number of PDFs iterated: 3100\n",
      "Chunk 32 completed. Number of PDFs iterated: 3200\n",
      "Chunk 33 completed. Number of PDFs iterated: 3300\n",
      "Chunk 34 completed. Number of PDFs iterated: 3400\n",
      "Chunk 35 completed. Number of PDFs iterated: 3500\n",
      "Chunk 36 completed. Number of PDFs iterated: 3600\n",
      "Chunk 37 completed. Number of PDFs iterated: 3700\n",
      "Chunk 38 completed. Number of PDFs iterated: 3800\n",
      "Chunk 39 completed. Number of PDFs iterated: 3900\n",
      "Chunk 40 completed. Number of PDFs iterated: 4000\n",
      "Chunk 41 completed. Number of PDFs iterated: 4100\n",
      "Chunk 42 completed. Number of PDFs iterated: 4200\n",
      "Chunk 43 completed. Number of PDFs iterated: 4300\n",
      "Chunk 44 completed. Number of PDFs iterated: 4400\n",
      "Chunk 45 completed. Number of PDFs iterated: 4500\n",
      "Chunk 46 completed. Number of PDFs iterated: 4600\n",
      "Chunk 47 completed. Number of PDFs iterated: 4700\n",
      "Chunk 48 completed. Number of PDFs iterated: 4800\n",
      "Chunk 49 completed. Number of PDFs iterated: 4900\n",
      "Chunk 50 completed. Number of PDFs iterated: 5000\n",
      "Chunk 51 completed. Number of PDFs iterated: 5100\n",
      "Chunk 52 completed. Number of PDFs iterated: 5200\n",
      "Chunk 53 completed. Number of PDFs iterated: 5300\n",
      "Chunk 54 completed. Number of PDFs iterated: 5400\n",
      "Chunk 55 completed. Number of PDFs iterated: 5500\n",
      "Chunk 56 completed. Number of PDFs iterated: 5600\n",
      "Chunk 57 completed. Number of PDFs iterated: 5700\n",
      "Chunk 58 completed. Number of PDFs iterated: 5800\n",
      "Chunk 59 completed. Number of PDFs iterated: 5900\n",
      "Chunk 60 completed. Number of PDFs iterated: 6000\n",
      "Chunk 61 completed. Number of PDFs iterated: 6100\n",
      "Chunk 62 completed. Number of PDFs iterated: 6200\n",
      "Chunk 63 completed. Number of PDFs iterated: 6300\n",
      "Chunk 64 completed. Number of PDFs iterated: 6400\n",
      "Chunk 65 completed. Number of PDFs iterated: 6500\n",
      "Chunk 66 completed. Number of PDFs iterated: 6600\n",
      "Chunk 67 completed. Number of PDFs iterated: 6700\n",
      "Chunk 68 completed. Number of PDFs iterated: 6800\n",
      "Chunk 69 completed. Number of PDFs iterated: 6900\n",
      "Chunk 70 completed. Number of PDFs iterated: 7000\n",
      "Chunk 71 completed. Number of PDFs iterated: 7100\n",
      "Chunk 72 completed. Number of PDFs iterated: 7200\n",
      "Chunk 73 completed. Number of PDFs iterated: 7300\n",
      "Chunk 74 completed. Number of PDFs iterated: 7400\n",
      "Chunk 75 completed. Number of PDFs iterated: 7500\n",
      "Chunk 76 completed. Number of PDFs iterated: 7600\n",
      "Chunk 77 completed. Number of PDFs iterated: 7700\n",
      "Chunk 78 completed. Number of PDFs iterated: 7800\n",
      "Chunk 79 completed. Number of PDFs iterated: 7900\n",
      "Chunk 80 completed. Number of PDFs iterated: 8000\n",
      "Chunk 81 completed. Number of PDFs iterated: 8100\n",
      "Chunk 82 completed. Number of PDFs iterated: 8200\n",
      "Chunk 83 completed. Number of PDFs iterated: 8300\n",
      "Chunk 84 completed. Number of PDFs iterated: 8400\n",
      "Chunk 85 completed. Number of PDFs iterated: 8500\n",
      "Chunk 86 completed. Number of PDFs iterated: 8600\n",
      "Chunk 87 completed. Number of PDFs iterated: 8700\n",
      "Chunk 88 completed. Number of PDFs iterated: 8800\n",
      "Chunk 89 completed. Number of PDFs iterated: 8900\n",
      "Chunk 90 completed. Number of PDFs iterated: 9000\n",
      "Chunk 91 completed. Number of PDFs iterated: 9100\n",
      "Chunk 92 completed. Number of PDFs iterated: 9160\n",
      "69576\n",
      "Total number of PDFs iterated: 9160\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "import re\n",
    "\n",
    "unique_words = set()\n",
    "\n",
    "def extract_text_from_pdf(pdf_file_path):\n",
    "    reader = PdfReader(pdf_file_path)\n",
    "    text = ''\n",
    "    stop_extracting = False\n",
    "    for page_num in range(1, len(reader.pages)):\n",
    "        if stop_extracting:\n",
    "            break\n",
    "        page = reader.pages[page_num]\n",
    "        extracted_text = page.extract_text()\n",
    "        if f'{page_num+1}/{page_num+1}' in extracted_text:\n",
    "            text += extracted_text.split(f'{page_num+1}/{page_num+1}')[0]\n",
    "            stop_extracting = True\n",
    "        else:\n",
    "            text += extracted_text\n",
    "    return text\n",
    "\n",
    "def remove_punctuation_and_numbers(text):\n",
    "    # Remove punctuation marks and numbers using regular expressions\n",
    "    clean_text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    clean_text = re.sub(r'\\d+', '', clean_text)\n",
    "    # Remove extra spaces\n",
    "    clean_text = re.sub(r'\\s+', ' ', clean_text)\n",
    "    return clean_text.strip()\n",
    "\n",
    "def extract_text_from_directory(directory_path):\n",
    "      # Use set to store unique words\n",
    "    num_pdfs = 0\n",
    "    pdf_files = [filename for filename in os.listdir(directory_path) if filename.endswith('.pdf')]\n",
    "    num_chunks = (len(pdf_files) + 99) // 100  # Calculate number of chunks\n",
    "    for chunk_num in range(num_chunks):\n",
    "        chunk_start = chunk_num * 100\n",
    "        chunk_end = min((chunk_num + 1) * 100, len(pdf_files))\n",
    "        chunk_pdfs = pdf_files[chunk_start:chunk_end]\n",
    "        for filename in chunk_pdfs:\n",
    "            num_pdfs += 1\n",
    "            pdf_file_path = os.path.join(directory_path, filename)\n",
    "            extracted_text = extract_text_from_pdf(pdf_file_path)\n",
    "            cleaned_text = remove_punctuation_and_numbers(extracted_text)\n",
    "            unique_words.update(cleaned_text.split())  # Update set with unique words\n",
    "        print(f\"Chunk {chunk_num + 1} completed. Number of PDFs iterated: {num_pdfs}\")\n",
    "    print(len(unique_words))\n",
    "    print(f\"Total number of PDFs iterated: {num_pdfs}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    directory_path = r'C:\\Stories'\n",
    "    extract_text_from_directory(directory_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words have been written to separate_words.txt\n"
     ]
    }
   ],
   "source": [
    "# Assuming `unique_words` is properly defined elsewhere in your code\n",
    "unique_words = list(unique_words)\n",
    "\n",
    "# Define the file name\n",
    "file_name = \"separate_words.txt\"\n",
    "\n",
    "try:\n",
    "    # Open the file in write mode with UTF-8 encoding\n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        # Iterate over the list\n",
    "        for item in unique_words:\n",
    "            # Write each element followed by a newline character\n",
    "            file.write(item + '\\n')\n",
    "    print(\"Unique words have been written to\", file_name)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
